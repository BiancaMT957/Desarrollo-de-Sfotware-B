# Ejercicios obligatorios (respuestas)

A continuación se presentan las respuestas a los ejercicios obligatorios listados en la actividad.

## Ejercicio 1 — Estrategia de "pruebas unitarias" y "pruebas de contrato" combinadas

1. Diseño de módulos declarativos (interfaz)
   - network
     - variables:
       - var.vpc_cidr (string)
       - var.public_subnets (list(string))
       - var.private_subnets (list(string))
     - outputs:
       - vpc_id (string)
       - public_subnets (list(object({ id=string, cidr=string })))
       - private_subnets (list(object({ id=string, cidr=string })))
   - compute
     - variables:
       - var.instance_count (number)
       - var.instance_type (string)
       - var.subnet_ids (list(string))
     - outputs:
       - instance_ids (list(string))
       - instance_private_ips (list(string))
   - storage
     - variables:
       - var.bucket_names (list(string))
     - outputs:
       - buckets (map(object({ name=string, arn=string })))
   - Convenios de naming y outputs:
     - Usar snake_case para variables y outputs.
     - Outputs que representan colecciones usar prefijo plural (e.g., public_subnets).
     - Estandarizar objetos: cada subnet debe tener { id, cidr, az } si aplica.
     - Documentar tipos en `outputs.tf` y en README del módulo.
   - Beneficio: los contract tests verifican la presencia, tipo y shape de estos outputs sin necesidad de recursos reales.

2. Casos límite sin recursos externos
   - Escenarios de inputs inválidos a detectar:
     - vpc_cidr inválido: "300.0.0.0/16" o máscara CIDR fuera de 0-32.
     - instance_count <= 0 o instance_count > 1000 (límite arbitrario).
     - subnets con CIDR solapado con VPC o entre sí.
     - hostname con espacios o caracteres no permitidos en `dns` (p. ej. "bad host").
   - Herramientas / comandos:
     - `terraform validate` — válida sintaxis HCL y algunas validaciones estáticas (por ejemplo, required vars).
     - `terraform plan` — detecta problemas semánticos y produce el plan (recomendado con `-input=false -no-color`).
     - `terraform output -json` — para contract tests, recuperar outputs y validar shape/type.
     - `terraform console` — permite evaluar expresiones y funciones locales para unit tests de lógica.
   - Por qué: `validate` es rápido y detecta errores HCL; `plan` detecta errores lógicos y cambios no deseados; `output -json` facilita pruebas de contrato automatizadas contra un esquema.

3. Métrica de cobertura de contrato
   - Método de cuantificación:
     - Definir lista canónica de outputs documentados (ej. en `outputs_schema.json`).
     - Para cada contract test, marcar qué campos del esquema son verificados.
     - Cobertura = (número de campos verificados / número total de campos documentados) * 100.
   - Balance exhaustividad vs mantenimiento:
     - Priorizar campos "estables" y críticos (ids, IPs, ARNs) para pruebas obligatorias.
     - Marcar campos frágiles (timestamps, autogenerated metadata) como "opcionales" en el esquema y excluirlos de la cobertura obligatoria.
     - Mantener tests parametrizados y usar `schemavalidator` con reglas que acepten variaciones razonables.

---

## Ejercicio 2.4 — Secuenciación de dependencias (integration test local)

- Ejecución encadenada (sin código):
  1. Aplicar `network` en un workspace/estado temporal: `terraform init -backend=false && terraform apply -auto-approve`.
  2. Recuperar outputs: subnets, vpc_id con `terraform output -json`.
  3. Inyectar esos outputs como variables en la ejecución de `compute` (por ejemplo, escribir un `tfvars` temporal con `subnet_ids = [...]`), luego `terraform init -backend=false && terraform apply -auto-approve` en `compute`.
  4. Recuperar `compute` outputs (instance IDs, IPs) y pasarlos a `storage` si es necesario.
- Garantizar consumo correcto de outputs sin scripts externos complicados:
  - Usar `terraform output -json` y generar archivos `*.auto.tfvars.json` en el directorio del módulo siguiente; Terraform los carga automáticamente.
  - Alternativa: usar un "driver" (bash/python) que haga:
    - `terraform output -json` -> parsea -> escribe `modules/compute/auto_inputs.auto.tfvars.json`.
  - Con este patrón no se necesitan manipular estados remotos ni pasar variables por la línea de comandos continuamente.

## Ejercicio 2.6 — Pruebas de interacción gradual (depth levels)

- Level 1 (light): Validación de shape/legibilidad de outputs compartidos
  - Verifica que outputs esperados existen y cumplen el contrato (tipos, keys).
  - Ideal cuando se valida integración lógica entre equipos o cambios en interfaces.
- Level 2 (deep): Validación de flujo real de datos
  - Valida funcionamiento real: p.ej., escritura en bucket, conectividad entre instancias y DB.
  - Usar contenedores locales o proveedores simulados para evitar coste real.
- Cuándo usar cada uno:
  - Level 1: ante cambios de interfaz o en PRs rápidos; es rápido y de bajo coste.
  - Level 2: antes de release mayor, al cambiar componentes críticos o comportamiento de red/storage.
- Evitar solapamientos:
  - Definir alcance claro para cada test y etiquetarlos (e.g., smoke, integration:light, integration:deep).
  - Reusar fixtures/resultados: si un deep test ya valida un flujo, no duplicar comprobaciones en light tests; en vez de eso los light tests validan únicamente la presencia de outputs.

---

## Ejercicio 3.7 — Pruebas de humo locales ultrarrápidos

- Tres comandos rápidos por módulo:
  1. `terraform fmt -check` — asegura estilo y evita cambios triviales que rompan diffs.
  2. `terraform validate` — valida sintaxis y comprobaciones estáticas.
  3. `terraform plan -refresh=false -input=false` — genera plan sin tocar estados remotos, detecta errores semánticos inmediatos.
- Justificación:
  - `fmt` evita falsos positivos por formato y estandariza el código.
  - `validate` atrapa errores HCL y problemas básicos.
  - `plan -refresh=false` es rápido (no consulta recursos reales) y detecta errores de configuración y referencias rotas; `-refresh=false` evita esperas por recursos existentes.

## Ejercicio 3.8 — Planes "golden" para regresión

- Procedimiento para generar/versionar `plan-base.json`:
  1. Ejecutar plan controlado: `terraform plan -out=plan_base.tfplan`.
  2. Convertir a JSON: `terraform show -json plan_base.tfplan > plans/plan_base_network.json`.
  3. Normalizar: aplicar filtro que elimine campos volátiles (timestamps, paths, UUIDs).
  4. Commit de `plans/plan_base_network.json` con mensaje estandarizado `chore(plans): update plan_base_network.json — reason`.
- Detectar diferencias semánticas evitando falsos positivos:
  - Normalizar ambos JSONs (orden de keys, eliminar metadata no relevante).
  - Comparar solo `resource_changes` y dentro de cada recurso, comparar atributos relevantes (p. ej. name, type, config/values).
  - Usar herramientas como `jq --sort-keys` y un script que ignore campos listados en una "allowlist" de variaciones.
  - Si el diff muestra solo metadatos permitidos, no fallar CI; si hay cambios en `resource_changes[*].change.after` o en counts, marcar alerta.

---

## Ejercicio 4.10 — E2E sin IaC real (Escenario)

- Descripción del test E2E local:
  1. Aplicar `network`, `compute` y `storage` localmente (con drivers/containers que simulan recursos).
  2. Levantar un servicio Flask dentro de un contenedor (provisioner local-exec o `docker run`) conectado a la red creada por `network`.
  3. Ejecutar peticiones HTTP desde el host:
     - GET / -> esperar 200.
     - POST /data -> validar payload y persitencia en `storage` simulado (p. ej. un archivo escrito en un volumen compartido).
  4. Validar que el balanceador/puerta de enlace configurada por `network` enruta correctamente al contenedor.
- Métricas a examinar:
  - status code (200, 4xx, 5xx),
  - latencia (p95 < umbral definido),
  - payload esperado y schema JSON.
- Integración en suite sin CI externo:
  - Incluir el test en `run_all.sh` tras aplicar módulos, ejecutar un pequeño cliente (curl/jq) y emitir resultados en `e2e_http_check.txt`.

---

## Ejercicio 5.13 — Mapeo de pruebas al pipeline local

- Secuencia (sin CI), respetando pirámide:
  1. Unit tests (fast, locales): validar funciones/locals con `terraform console` y tests de outputs.
  2. Smoke/contract: `run_smoke.sh` (fmt, validate, plan -refresh=false, output contract checks).
  3. Integration: apply encadenado (network -> compute -> storage) en entornos temporales.
  4. E2E: pruebas en contenedores y comprobaciones HTTP.
- Medir tiempos:
  - Instrumentar cada fase con timestamps (start/end) y almacenar en `timings.json`.
  - Analizar resultados periódicamente y priorizar optimizaciones (por ejemplo, paralelizar smoke tests de módulos independientes).

## Ejercicio 6.18 — Automatización local de la suite (run_all.sh)

- Plan:
  - `run_all.sh`:
    1. `terraform destroy` en módulos temporales (si existen) para limpiar estados previos.
    2. Ejecutar unit tests (uso de `terraform console` y validadores locales).
    3. Ejecutar `run_smoke.sh`.
    4. Ejecutar integration (apply encadenado) y E2E.
    5. Al final imprimir resumen por categoría (passed/failed).
  - Notificaciones locales:
    - Enviar correo vía `sendmail` o `mail` configurado localmente, o bien integrar con webhook de Slack usando `curl` si el usuario tiene un *incoming webhook*. Scripts incluyen un hook opcional para notificaciones.

## Ejercicio 7 — Módulos `firewall` y `dns` y pruebas unitarias

- `firewall`:
  - Inputs: lista de reglas objeto { port = number, cidr = string, proto = string }.
  - Salida: `policy_json` con esquema fijo: { version, rules: [ { port, cidr, proto } ] }.
  - Unit tests (sugeridos):
    - Proveer conjunto válido -> `terraform output -json` y comparar schema (keys y tipos).
    - Proveer regla con CIDR inválido -> `terraform validate` (o validación con `regex` en variable).
- `dns`:
  - Inputs: mapa `hostnames = { "app" = "10.0.0.5" }`.
  - Validation: nombre de host con regex `^[a-z0-9]([a-z0-9-]{0,61}[a-z0-9])?$`.
  - Output: `resolution_map` map(hostname=>ip).
- Unit tests con solo `terraform console` y `terraform output -json`:
  - Usar `terraform init -backend=false && terraform apply -auto-approve` en un workspace de test (local), luego `terraform output -json` y validar con `jq` las keys y tipos.

## Ejercicio 10 — Script `run_smoke.sh`

- El script:
  - Itera sobre `modules/*`.
  - Para cada módulo:
    1. `terraform init -backend=false` (silencioso).
    2. `terraform fmt -check`.
    3. `terraform validate`.
    4. `terraform plan -refresh=false -out=/tmp/plan_$module`.
    5. `terraform show -json /tmp/plan_$module` y extrae un key contractual (por ejemplo, número de subnets).
  - El script usa timeouts por módulo y paraleliza hasta N módulos para cumplir el objetivo de <30s en máquinas razonables.



---

Fin de respuestas obligatorias.
